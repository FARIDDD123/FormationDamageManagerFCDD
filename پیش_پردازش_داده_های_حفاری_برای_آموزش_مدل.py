# -*- coding: utf-8 -*-
"""Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­ÙØ§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZmRz0hcfTQ63QNm2wIcQ8FlRWWLP4Fqw
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import pandas as pd
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
import numpy as np

# Ù…Ø³ÛŒØ± Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù… Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
RAW_DATA_PATH = '/content/drive/MyDrive/24may_amin_dataset'
PROCESSED_PATH = os.path.join('/content/cleaned_dataset.parquet')
OUTLIERS_PATH = os.path.join('/content/outliers/outliers.parquet')

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ CSV ÛŒØ§ Parquet
def load_raw_data(path):
    files = [f for f in os.listdir(path) if f.endswith(('.csv', '.parquet'))]
    if not files:
        print("ğŸš¨ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù… ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return None
    file = files[0]
    print(f"ğŸ“‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„: {file}")
    file_path = os.path.join(path, file)
    if file.endswith('.csv'):
        return pd.read_csv(file_path)
    else:
        return pd.read_parquet(file_path)

# Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
def preprocess_data(df):
    print("ğŸ” Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡...")
    df = df.dropna()  # ÛŒØ§ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø§Ø² imputing Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒ

    print("ğŸ”¬ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ...")
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    scaler = StandardScaler()
    if numeric_cols:
        df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

    print("ğŸ”¤ Encoding ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ...")
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    for col in categorical_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

    return df, numeric_cols

# Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª
def detect_outliers(df, numeric_cols):
    print("ğŸ“Š Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª...")
    outlier_indices = set()
    for col in numeric_cols:
        col_data = df[col]
        # IQR Method
        Q1 = col_data.quantile(0.25)
        Q3 = col_data.quantile(0.75)
        IQR = Q3 - Q1
        outlier_step = 1.5 * IQR
        iqr_outliers = df[(col_data < Q1 - outlier_step) | (col_data > Q3 + outlier_step)].index
        outlier_indices.update(iqr_outliers)

        # Z-Score Method
        z_scores = (col_data - col_data.mean()) / col_data.std()
        z_outliers = df[np.abs(z_scores) > 3].index
        outlier_indices.update(z_outliers)

    outliers_df = df.loc[list(outlier_indices)]
    cleaned_df = df.drop(index=outlier_indices)

    return cleaned_df, outliers_df

# Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù…Ù†
def save_dataframe(df, path, original_columns):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    if df.empty:
        print(f"âš ï¸ DataFrame Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¯Ø± {path}")
        pd.DataFrame(columns=original_columns).to_parquet(path, index=False)
    else:
        df.to_parquet(path, index=False)
        print(f"âœ… Ø¯Ø§Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {path}")

# Ø§Ø¬Ø±Ø§ÛŒ Pipeline
def run_pipeline():
    df = load_raw_data(RAW_DATA_PATH)
    if df is None or df.empty:
        print("ğŸš¨ Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù… Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
        return

    original_columns = df.columns.tolist()
    processed_df, numeric_cols = preprocess_data(df)
    cleaned_df, outliers_df = detect_outliers(processed_df, numeric_cols)

    save_dataframe(cleaned_df, PROCESSED_PATH, original_columns)
    save_dataframe(outliers_df, OUTLIERS_PATH, original_columns)

    print("ğŸ‰ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯.")

if __name__ == "__main__":
    run_pipeline()

from google.colab import drive
import shutil

# Mount Google Drive
drive.mount('/content/drive')

# Ù…Ø³ÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ
input_path = '/content/datasets'
output_zip_path = '/content/datasets.zip'
destination_path = '/content/drive/MyDrive/datasets.zip'

# ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ
shutil.make_archive(output_zip_path.replace('.zip', ''), 'zip', input_path)
print(f"âœ… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯: {output_zip_path}")

# Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ Google Drive
shutil.move(output_zip_path, destination_path)
print(f"âœ… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ù…Ù†ØªÙ‚Ù„ Ø´Ø¯: {destination_path}")