{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------- Ø¨Ø®Ø´ 1: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ----------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from lightgbm import LGBMClassifier\n",
        "import mlflow\n",
        "from mlflow.models.signature import infer_signature\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§\n",
        "!pip install pandas pyarrow scikit-learn mlflow lightgbm confluent-kafka pyngrok --quiet\n",
        "\n",
        "# Ù†ØµØ¨ confluent-kafka Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø®Ø·Ø§\n",
        "try:\n",
        "    from confluent_kafka import Consumer\n",
        "except ImportError:\n",
        "    !pip install confluent-kafka\n",
        "    from confluent_kafka import Consumer\n",
        "\n",
        "# Ø¨Ø±Ø§ÛŒ Airflow (Ø¯Ø± Ù…Ø­ÛŒØ· ØºÛŒØ±-Colab Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯)\n",
        "try:\n",
        "    from airflow import DAG\n",
        "    from airflow.operators.python import PythonOperator\n",
        "    from datetime import datetime, timedelta\n",
        "except ImportError:\n",
        "    print(\"Airflow Ø¯Ø± Colab Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ù†ÛŒØ³Øª. DAG Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ· Airflow ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§Ø³Øª.\")\n",
        "\n",
        "# ---------- Ø¨Ø®Ø´ 2: Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Drive ----------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------- Ø¨Ø®Ø´ 3: ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² Kafka ----------\n",
        "def fetch_kafka_data():\n",
        "    conf = {\n",
        "    'bootstrap.servers': '0.tcp.ngrok.io:12345',  # Ø¢Ø¯Ø±Ø³ ngrok\n",
        "    'group.id': 'formation_damage_group',\n",
        "    'auto.offset.reset': 'earliest'\n",
        "}\n",
        "    try:\n",
        "        consumer = Consumer(conf)\n",
        "        consumer.subscribe(['formation_damage_topic'])\n",
        "        msg = consumer.poll(timeout=10.0)\n",
        "        if msg is None:\n",
        "            print(\"Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø² Kafka Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.\")\n",
        "            return None\n",
        "        data = pd.read_json(msg.value().decode('utf-8'))\n",
        "        print(\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø² Kafka Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² Kafka: {str(e)}\")\n",
        "        return None\n",
        "    finally:\n",
        "        consumer.close()\n",
        "\n",
        "# ---------- Ø¨Ø®Ø´ 4: Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯ÛŒØªØ§Ø³Øª ----------\n",
        "def preprocess_data(file_path=None, kafka_data=None):\n",
        "    columns_to_use = ['Formation', 'Fluid_Type', 'Completion_Type',\n",
        "                      'Temperature_C', 'Pressure_psi', 'Permeability_mD',\n",
        "                      'Porosity_pct', 'Damage_Type']\n",
        "\n",
        "    # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ÛŒØ§ Ø¬Ø¯ÛŒØ¯\n",
        "    if file_path:\n",
        "        df = pd.read_parquet(file_path, columns=columns_to_use)\n",
        "        print(\"Ø¯ÛŒØªØ§Ø³Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯.\")\n",
        "        print(f\"Ø§Ø¨Ø¹Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯ÛŒØªØ§Ø³Øª: {df.shape}\")\n",
        "    elif kafka_data is not None:\n",
        "        df = kafka_data[columns_to_use]\n",
        "        print(\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø² Kafka Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯.\")\n",
        "        print(f\"Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯: {df.shape}\")\n",
        "    else:\n",
        "        raise ValueError(\"Ù‡ÛŒÚ† Ù…Ù†Ø¨Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.\")\n",
        "\n",
        "    # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡\n",
        "    print(\"\\nÙ†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡:\")\n",
        "    display(df.head(3))\n",
        "\n",
        "    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡\n",
        "    initial_count = len(df)\n",
        "    df = df.dropna(subset=['Damage_Type', 'Permeability_mD', 'Porosity_pct'])\n",
        "    print(f\"\\nØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {initial_count - len(df)}\")\n",
        "    print(f\"Ø§Ø¨Ø¹Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¯ÛŒØªØ§Ø³Øª: {df.shape}\")\n",
        "\n",
        "    # Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø³ØªÙˆÙ† Ù‡Ø¯Ù\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['Damage_Type'] = label_encoder.fit_transform(df['Damage_Type'])\n",
        "\n",
        "    # Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©ÛŒÙÛŒ\n",
        "    categorical_cols = ['Formation', 'Fluid_Type', 'Completion_Type']\n",
        "\n",
        "    X = df.drop(columns=['Damage_Type'])\n",
        "    y = df['Damage_Type']\n",
        "\n",
        "    # Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ØªØµØ§Ø¯ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯\n",
        "    if len(df) > 100000:\n",
        "        sample_size = min(100000, len(df))\n",
        "        X = X.sample(n=sample_size, random_state=42)\n",
        "        y = y.loc[X.index]\n",
        "\n",
        "    return X, y, label_encoder, categorical_cols\n",
        "\n",
        "# ---------- Ø¨Ø®Ø´ 5: Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ ----------\n",
        "def train_model(X, y, categorical_cols, previous_run_id=None):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡:\")\n",
        "    print(f\"Ø¯Ø§Ø¯Ù‡ Ø¢Ù…ÙˆØ²Ø´: {X_train.shape[0]} Ù†Ù…ÙˆÙ†Ù‡\")\n",
        "    print(f\"Ø¯Ø§Ø¯Ù‡ Ø¢Ø²Ù…ÙˆÙ†: {X_test.shape[0]} Ù†Ù…ÙˆÙ†Ù‡\")\n",
        "\n",
        "    # ØªÙ†Ø¸ÛŒÙ… MLflow\n",
        "    !mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri /tmp/mlflow &>./mlflow.log &\n",
        "    !sleep 3\n",
        "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "    mlflow.set_experiment(\"FormationDamageFast\")\n",
        "\n",
        "    # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„\n",
        "    model_params = {\n",
        "        'n_estimators': 200,\n",
        "        'max_depth': 7,\n",
        "        'learning_rate': 0.1,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'verbose': -1,\n",
        "        'categorical_feature': categorical_cols  # Ù…Ø¯ÛŒØ±ÛŒØª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©ØªÚ¯ÙˆØ±ÛŒÚ©Ø§Ù„\n",
        "    }\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        model = LGBMClassifier(**model_params)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
        "        train_pred = model.predict(X_train)\n",
        "        test_pred = model.predict(X_test)\n",
        "\n",
        "        metrics = {\n",
        "            'train_accuracy': accuracy_score(y_train, train_pred),\n",
        "            'test_accuracy': accuracy_score(y_test, test_pred)\n",
        "        }\n",
        "\n",
        "        # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ\n",
        "        if previous_run_id:\n",
        "            try:\n",
        "                previous_model = mlflow.lightgbm.load_model(f\"runs:/{previous_run_id}/model\")\n",
        "                previous_accuracy = accuracy_score(y_test, previous_model.predict(X_test))\n",
        "                metrics['accuracy_improvement'] = metrics['test_accuracy'] - previous_accuracy\n",
        "                print(f\"Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‚Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ: {metrics['accuracy_improvement']:.4f}\")\n",
        "            except:\n",
        "                print(\"Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.\")\n",
        "                metrics['accuracy_improvement'] = 0.0\n",
        "\n",
        "        # Ø«Ø¨Øª Ø¯Ø± MLflow\n",
        "        signature = infer_signature(X_train, model.predict(X_train))\n",
        "        mlflow.log_params(model_params)\n",
        "        mlflow.log_metrics(metrics)\n",
        "        mlflow.lightgbm.log_model(model, \"model\", signature=signature)\n",
        "\n",
        "        print(\"\\nÙ†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ:\")\n",
        "        print(f\"Ø¯Ù‚Øª Ø¢Ù…ÙˆØ²Ø´: {metrics['train_accuracy']:.4f}\")\n",
        "        print(f\"Ø¯Ù‚Øª Ø¢Ø²Ù…ÙˆÙ†: {metrics['test_accuracy']:.4f}\")\n",
        "        print(\"\\nÚ¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:\")\n",
        "        print(classification_report(y_test, test_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "        return model, metrics, mlflow.active_run().info.run_id\n",
        "\n",
        "# ---------- Ø¨Ø®Ø´ 6: Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ùˆ LabelEncoder ----------\n",
        "def save_artifacts(model, label_encoder, metrics):\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    model_path = f\"fast_formation_damage_model_{timestamp}.pkl\"\n",
        "    encoder_path = f\"label_encoder_{timestamp}.pkl\"\n",
        "\n",
        "    joblib.dump(model, model_path, compress=3)\n",
        "    joblib.dump(label_encoder, encoder_path)\n",
        "    !cp \"{model_path}\" \"/content/drive/MyDrive/\"\n",
        "    !cp \"{encoder_path}\" \"/content/drive/MyDrive/\"\n",
        "\n",
        "    print(f\"\\nÙ…Ø¯Ù„ Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: /content/drive/MyDrive/{model_path}\")\n",
        "    print(f\"LabelEncoder Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: /content/drive/MyDrive/{encoder_path}\")\n",
        "\n",
        "# ---------- Ø¨Ø®Ø´ 7: ØªØ¹Ø±ÛŒÙ DAG Ø¨Ø±Ø§ÛŒ Airflow (Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ· ØºÛŒØ±-Colab) ----------\n",
        "try:\n",
        "    default_args = {\n",
        "        'owner': 'airflow',\n",
        "        'depends_on_past': False,\n",
        "        'email_on_failure': False,\n",
        "        'email_on_retry': False,\n",
        "        'retries': 1,\n",
        "        'retry_delay': timedelta(minutes=5),\n",
        "    }\n",
        "\n",
        "    with DAG(\n",
        "        'formation_damage_retraining',\n",
        "        default_args=default_args,\n",
        "        description='Retraining Formation Damage Model every 7 days',\n",
        "        schedule_interval=timedelta(days=7),\n",
        "        start_date=datetime(2025, 5, 22),\n",
        "        catchup=False,\n",
        "    ) as dag:\n",
        "\n",
        "        def airflow_fetch_data():\n",
        "            kafka_data = fetch_kafka_data()\n",
        "            if kafka_data is not None:\n",
        "                X, y, label_encoder, categorical_cols = preprocess_data(kafka_data=kafka_data)\n",
        "                return X, y, label_encoder, categorical_cols\n",
        "            else:\n",
        "                file_path = '/content/drive/MyDrive/formation_damage_optimized.parquet'\n",
        "                return preprocess_data(file_path=file_path)\n",
        "\n",
        "        def airflow_train_model(ti):\n",
        "            X, y, label_encoder, categorical_cols = ti.xcom_pull(task_ids='fetch_data')\n",
        "            previous_run_id = ti.xcom_pull(task_ids='train_model', key='run_id') if ti.xcom_pull(task_ids='train_model') else None\n",
        "            model, metrics, run_id = train_model(X, y, categorical_cols, previous_run_id)\n",
        "            ti.xcom_push(key='run_id', value=run_id)\n",
        "            return model, label_encoder, metrics\n",
        "\n",
        "        def airflow_save_artifacts(ti):\n",
        "            model, label_encoder, metrics = ti.xcom_pull(task_ids='train_model')\n",
        "            save_artifacts(model, label_encoder, metrics)\n",
        "\n",
        "        task_fetch = PythonOperator(\n",
        "            task_id='fetch_data',\n",
        "            python_callable=airflow_fetch_data,\n",
        "            provide_context=True\n",
        "        )\n",
        "\n",
        "        task_train = PythonOperator(\n",
        "            task_id='train_model',\n",
        "            python_callable=airflow_train_model,\n",
        "            provide_context=True\n",
        "        )\n",
        "\n",
        "        task_save = PythonOperator(\n",
        "            task_id='save_artifacts',\n",
        "            python_callable=airflow_save_artifacts,\n",
        "            provide_context=True\n",
        "        )\n",
        "\n",
        "        task_fetch >> task_train >> task_save\n",
        "except:\n",
        "    print(\"DAG ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø± ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± Ù…Ø­ÛŒØ· Airflow Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª.\")\n",
        "\n",
        "# ---------- Ø¨Ø®Ø´ 8: Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¯Ø± Colab ----------\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² Kafka\n",
        "        kafka_data = fetch_kafka_data()\n",
        "        if kafka_data is None:\n",
        "            print(\"Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² Kafka Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ù¾Ø§Ø±Ø§Ú©Øª...\")\n",
        "            file_path = '/content/drive/MyDrive/formation_damage_optimized.parquet'\n",
        "            X, y, label_encoder, categorical_cols = preprocess_data(file_path=file_path)\n",
        "        else:\n",
        "            X, y, label_encoder, categorical_cols = preprocess_data(kafka_data=kafka_data)\n",
        "\n",
        "        # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
        "        model, metrics, run_id = train_model(X, y, categorical_cols)\n",
        "\n",
        "        # Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ\n",
        "        save_artifacts(model, label_encoder, metrics)\n",
        "\n",
        "        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ngrok Ø¨Ø±Ø§ÛŒ MLflow\n",
        "        !pip install pyngrok --quiet\n",
        "        from pyngrok import ngrok\n",
        "        public_url = ngrok.connect(5000)\n",
        "        print(f\"MLflow URL: {public_url}\")\n",
        "\n",
        "        from IPython.display import IFrame\n",
        "        IFrame(src=\"http://localhost:5000\", width=\"100%\", height=600)\n",
        "    except Exception as e:\n",
        "        print(f\"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "QMNH_1Wq_Iin",
        "outputId": "ff0c265a-820f-4500-cd0a-ec29ba5d1792"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.6/3.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m3.3/3.8 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hAirflow Ø¯Ø± Colab Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ù†ÛŒØ³Øª. DAG Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ· Airflow ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "DAG ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø± ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± Ù…Ø­ÛŒØ· Airflow Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª.\n",
            "Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø² Kafka Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.\n",
            "Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² Kafka Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ù¾Ø§Ø±Ø§Ú©Øª...\n",
            "Ø¯ÛŒØªØ§Ø³Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯.\n",
            "Ø§Ø¨Ø¹Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯ÛŒØªØ§Ø³Øª: (10500000, 8)\n",
            "\n",
            "Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Formation   Fluid_Type Completion_Type  Temperature_C  Pressure_psi  \\\n",
              "0  Dolomite    Oil-Based           Liner     103.802612   2508.131348   \n",
              "1     Shale  Water-Based           Liner     328.736755  17978.121094   \n",
              "2  Dolomite  Water-Based      Perforated      80.249832   5548.513184   \n",
              "\n",
              "   Permeability_mD  Porosity_pct         Damage_Type  \n",
              "0       382.382812     22.198469  Filtration Problem  \n",
              "1      1586.557373      3.340905  Corrosion Cracking  \n",
              "2       425.555878     11.398964  Corrosion Cracking  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3bb98dd-1dd3-4ef9-97a4-3685d80ea055\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Formation</th>\n",
              "      <th>Fluid_Type</th>\n",
              "      <th>Completion_Type</th>\n",
              "      <th>Temperature_C</th>\n",
              "      <th>Pressure_psi</th>\n",
              "      <th>Permeability_mD</th>\n",
              "      <th>Porosity_pct</th>\n",
              "      <th>Damage_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dolomite</td>\n",
              "      <td>Oil-Based</td>\n",
              "      <td>Liner</td>\n",
              "      <td>103.802612</td>\n",
              "      <td>2508.131348</td>\n",
              "      <td>382.382812</td>\n",
              "      <td>22.198469</td>\n",
              "      <td>Filtration Problem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shale</td>\n",
              "      <td>Water-Based</td>\n",
              "      <td>Liner</td>\n",
              "      <td>328.736755</td>\n",
              "      <td>17978.121094</td>\n",
              "      <td>1586.557373</td>\n",
              "      <td>3.340905</td>\n",
              "      <td>Corrosion Cracking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dolomite</td>\n",
              "      <td>Water-Based</td>\n",
              "      <td>Perforated</td>\n",
              "      <td>80.249832</td>\n",
              "      <td>5548.513184</td>\n",
              "      <td>425.555878</td>\n",
              "      <td>11.398964</td>\n",
              "      <td>Corrosion Cracking</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3bb98dd-1dd3-4ef9-97a4-3685d80ea055')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3bb98dd-1dd3-4ef9-97a4-3685d80ea055 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3bb98dd-1dd3-4ef9-97a4-3685d80ea055');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b2a9ef06-6a67-40a5-a9b5-77c6f0906457\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2a9ef06-6a67-40a5-a9b5-77c6f0906457')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b2a9ef06-6a67-40a5-a9b5-77c6f0906457 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"        print(f\\\"\\u062e\\u0637\\u0627 \\u062f\\u0631 \\u0627\\u062c\\u0631\\u0627\\u06cc \\u0627\\u0648\\u0644\\u06cc\\u0647: {str(e)}\\\")\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Formation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Shale\",\n          \"Dolomite\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluid_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Water-Based\",\n          \"Oil-Based\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Completion_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Perforated\",\n          \"Liner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature_C\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          103.8026123046875,\n          328.73675537109375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pressure_psi\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2508.13134765625,\n          17978.12109375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Permeability_mD\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          382.3828125,\n          1586.557373046875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Porosity_pct\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          22.198469161987305,\n          3.340904712677002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Damage_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Corrosion Cracking\",\n          \"Filtration Problem\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: 0\n",
            "Ø§Ø¨Ø¹Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¯ÛŒØªØ§Ø³Øª: (10500000, 8)\n",
            "\n",
            "ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡:\n",
            "Ø¯Ø§Ø¯Ù‡ Ø¢Ù…ÙˆØ²Ø´: 80000 Ù†Ù…ÙˆÙ†Ù‡\n",
            "Ø¯Ø§Ø¯Ù‡ Ø¢Ø²Ù…ÙˆÙ†: 20000 Ù†Ù…ÙˆÙ†Ù‡\n",
            "\n",
            "Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ:\n",
            "Ø¯Ù‚Øª Ø¢Ù…ÙˆØ²Ø´: 0.4374\n",
            "Ø¯Ù‚Øª Ø¢Ø²Ù…ÙˆÙ†: 0.1239\n",
            "\n",
            "Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           Clay & Iron       0.09      0.07      0.08      1917\n",
            "      Completion Issue       0.10      0.12      0.11      1927\n",
            "    Corrosion Cracking       0.21      0.21      0.21      2415\n",
            "       Drilling Damage       0.10      0.10      0.10      1846\n",
            "              Emulsion       0.11      0.11      0.11      1899\n",
            "    Filtration Problem       0.11      0.12      0.12      1895\n",
            " Fluid Incompatibility       0.19      0.15      0.17      2521\n",
            "            Fluid Loss       0.10      0.10      0.10      1885\n",
            "Rock/Fluid Interaction       0.10      0.11      0.10      1815\n",
            "     Ultra-Clean Fluid       0.11      0.12      0.12      1880\n",
            "\n",
            "              accuracy                           0.12     20000\n",
            "             macro avg       0.12      0.12      0.12     20000\n",
            "          weighted avg       0.13      0.12      0.12     20000\n",
            "\n",
            "ğŸƒ View run fortunate-flea-577 at: http://localhost:5000/#/experiments/483404947798218425/runs/8941376d24cf481891e5f8a08b1ebe6d\n",
            "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/483404947798218425\n",
            "\n",
            "Ù…Ø¯Ù„ Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: /content/drive/MyDrive/fast_formation_damage_model_20250522_075750.pkl\n",
            "LabelEncoder Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: /content/drive/MyDrive/label_encoder_20250522_075750.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-05-22T07:57:55+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}