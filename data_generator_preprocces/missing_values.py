import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

# 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ùˆ Ú©Ù¾ÛŒ Ú¯Ø±ÙØªÙ†
file_path = './datasets/text_corrected_data.parquet'
df = pd.read_parquet(file_path)
df_original = df.copy()

# 2. Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ù…Ù‚Ø¯Ø§Ø± Ú¯Ù…Ø´Ø¯Ù‡
missing_report = df.isnull().sum()
missing_report = missing_report[missing_report > 0]
print("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡:")
print(missing_report)

# ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù† (float Ùˆ int Ú©Ù„ÛŒ)
numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()

imputation_report = []

# 3. Ø§ÛŒÙ…Ù¾ÙˆØª Ø¨Ø§ CatBoost
for col in missing_report.index:
    if col not in numerical_cols:
        continue

    print(f"\nğŸ— Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒÙ…Ù¾ÙˆØªØ± Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†: {col}")

    train_data = df[df[col].notnull()]
    test_data = df[df[col].isnull()]

    if train_data.shape[0] < 50 or test_data.shape[0] == 0:
        print(f"â›” Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ CatBoost Ø¨Ø±Ø§ÛŒ {col} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        continue

    # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ Ø¬Ø² Ø³ØªÙˆÙ† Ù‡Ø¯Ù
    features_for_model = [c for c in numerical_cols if c != col]

    X_train = train_data[features_for_model].dropna(axis=1)
    y_train = train_data[col]
    X_test = test_data[X_train.columns]

    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø³Ø§Ø¯Ù‡
    X_train_part, X_val, y_train_part, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42
    )

    # Ù…Ø¯Ù„ CatBoost
    model = CatBoostRegressor(
        iterations=500,
        learning_rate=0.01,
        depth=6,
        loss_function='MAE',
        verbose=False,
        random_seed=42
    )

    model.fit(X_train_part, y_train_part, eval_set=(X_val, y_val), early_stopping_rounds=50)

    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ù‚Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ú¯Ù…Ø´Ø¯Ù‡
    y_pred_missing = model.predict(X_test)
    df.loc[df[col].isnull(), col] = y_pred_missing

    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    y_val_pred = model.predict(X_val)
    mae = mean_absolute_error(y_val, y_val_pred)
    mean_val = np.mean(y_val)
    percent_error = (mae / mean_val) * 100

    imputation_report.append({
        "Ø³ØªÙˆÙ†": col,
        "MAE": mae,
        "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ": mean_val,
        "Ø¯Ø±ØµØ¯ Ø®Ø·Ø§": round(percent_error, 2)
    })

# 4. Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
print("\nğŸ“ Ú¯Ø²Ø§Ø±Ø´ ØªØ®Ù…ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡ Ø¨Ø§ CatBoost:")
report_df = pd.DataFrame(imputation_report)
print(report_df)

# 5. Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯
output_file = './datasets/cleaned_without_missing.parquet'  # Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ .csv Ù‡Ù… Ø¨Ø²Ø§Ø±ÛŒ Ø§Ú¯Ø± Ø®ÙˆØ§Ø³ØªÛŒ
df.to_parquet(output_file, index=False)
print(f"\nâœ… ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§ÛŒÙ…Ù¾ÙˆØª Ø´Ø¯Ù‡ Ø¯Ø± '{output_file}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
