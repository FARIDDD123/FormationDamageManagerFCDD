import pandas as pd
import numpy as np
from scipy.stats import zscore
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler

file_path = './datasets/text_corrected_data.parquet'  # Ù†Ø§Ù… ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ
df = pd.read_parquet(file_path)

columns_to_check = ['Temperature_C', 'Pressure_psi', 'Permeability_mD', 'Flow_Rate_bbl_day']  # Ø¨Ù‡ Ø¯Ù„Ø®ÙˆØ§Ù‡ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡

# Ø±ÙˆØ´ IQR
def detect_outliers_iqr(df, columns):
    outliers = pd.DataFrame()
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outlier_rows = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        outliers = pd.concat([outliers, outlier_rows])
    return outliers.drop_duplicates()

# Ø±ÙˆØ´ Z-Score
def detect_outliers_zscore(df, columns, threshold=3):
    z_scores = np.abs(zscore(df[columns]))
    outliers = df[(z_scores > threshold).any(axis=1)]
    return outliers.drop_duplicates()

# Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª
iqr_outliers = detect_outliers_iqr(df, columns_to_check)
zscore_outliers = detect_outliers_zscore(df, columns_to_check)

# Ø§Ø¯ØºØ§Ù… Ù†ØªØ§ÛŒØ¬ Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø±
all_outliers = pd.concat([iqr_outliers, zscore_outliers]).drop_duplicates()

# Ø¢Ù…Ø§Ø±
total_rows = len(df)
iqr_count = len(iqr_outliers)
zscore_count = len(zscore_outliers)
combined_count = len(all_outliers)

print("ğŸ“Š Ø¢Ù…Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡:")
print(f"- Ø¨Ø§ Ø±ÙˆØ´ IQR: {iqr_count} ({iqr_count / total_rows:.2%})")
print(f"- Ø¨Ø§ Ø±ÙˆØ´ Z-Score: {zscore_count} ({zscore_count / total_rows:.2%})")
print(f"- Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø±: {combined_count} ({combined_count / total_rows:.2%})")

# Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø¯Ø± ÙØ§ÛŒÙ„
cleaned_file = './datasets/outliers.parquet'
all_outliers.to_parquet(cleaned_file, index=False)
print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø¯Ø± ÙØ§ÛŒÙ„ '{cleaned_file}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
